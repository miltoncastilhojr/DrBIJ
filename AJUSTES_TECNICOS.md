# Ajustes T√©cnicos - An√°lise Forense de √Åudio

## üîç 1. Picos e Sil√™ncios Ilus√≥rios (>60k)

### **Problema Identificado:**
- Picos acima de 60k s√£o **artifacts** ou **ru√≠do digital**
- Detec√ß√£o inadequada est√° capturando **falsos positivos**

### **Causas T√©cnicas:**
```python
# PROBLEMA: Par√¢metros muito sens√≠veis
peaks, _ = find_peaks(amp, height=np.percentile(amp, 90))  # 90% √© muito baixo
silences = np.where(amp < np.percentile(amp, 2))[0]       # 2% √© muito baixo
```

### **Solu√ß√µes Otimizadas:**

#### A) **Detec√ß√£o Inteligente de Picos:**
```python
def detectar_picos_inteligente(samples, sr):
    """Detec√ß√£o refinada de picos com filtros"""
    amp = np.abs(samples)
    
    # 1. Filtro de amplitude m√≠nima
    threshold_min = np.std(amp) * 2  # 2 desvios padr√£o
    
    # 2. Filtro de percentil mais rigoroso
    threshold_high = np.percentile(amp, 95)  # 95% em vez de 90%
    
    # 3. Dist√¢ncia m√≠nima entre picos (evita clusters)
    min_distance = int(sr * 0.1)  # 100ms m√≠nimo entre picos
    
    # 4. Detec√ß√£o com m√∫ltiplos crit√©rios
    peaks, properties = find_peaks(
        amp, 
        height=max(threshold_min, threshold_high),
        distance=min_distance,
        prominence=np.std(amp)  # Proemin√™ncia m√≠nima
    )
    
    return peaks, properties
```

#### B) **Detec√ß√£o Inteligente de Sil√™ncios:**
```python
def detectar_silencios_inteligente(samples, sr):
    """Detec√ß√£o refinada de sil√™ncios"""
    amp = np.abs(samples)
    
    # 1. Threshold din√¢mico baseado em estat√≠sticas
    noise_floor = np.percentile(amp, 5)  # 5% como ru√≠do de fundo
    silence_threshold = noise_floor * 3   # 3x o ru√≠do de fundo
    
    # 2. Dura√ß√£o m√≠nima de sil√™ncio (evita artifacts)
    min_silence_duration = int(sr * 0.5)  # 500ms m√≠nimo
    
    # 3. Detectar zonas silenciosas
    silence_mask = amp < silence_threshold
    
    # 4. Filtrar sil√™ncios muito curtos
    silence_regions = []
    start = None
    
    for i, is_silent in enumerate(silence_mask):
        if is_silent and start is None:
            start = i
        elif not is_silent and start is not None:
            duration = i - start
            if duration >= min_silence_duration:
                silence_regions.append((start, i, duration))
            start = None
    
    return silence_regions
```

---

## üìù 2. Transcri√ß√£o Sem Timestamp no Relat√≥rio

### **Raz√µes T√©cnicas Para Incluir Timestamps:**

#### A) **Valor Forense:**
- ‚úÖ **Sincroniza√ß√£o temporal** com eventos
- ‚úÖ **Verifica√ß√£o de autenticidade** 
- ‚úÖ **Correla√ß√£o com outras evid√™ncias**
- ‚úÖ **An√°lise de padr√µes temporais**

#### B) **An√°lise T√©cnica:**
- ‚úÖ **Velocidade de fala** (palavras/minuto)
- ‚úÖ **Pausas significativas** 
- ‚úÖ **Mudan√ßas de tom/ritmo**
- ‚úÖ **Identifica√ß√£o de edi√ß√µes**

### **Implementa√ß√£o Melhorada:**
```python
def gerar_transcricao_com_analise_temporal(result):
    """Transcri√ß√£o com an√°lise temporal detalhada"""
    
    transcricao_completa = []
    estatisticas_tempo = {
        'pausas_longas': [],
        'velocidade_fala': [],
        'duracao_total': 0
    }
    
    for i, segment in enumerate(result["segments"]):
        inicio = segment["start"]
        fim = segment["end"]
        texto = segment["text"].strip()
        duracao = fim - inicio
        
        # An√°lise de velocidade (palavras por minuto)
        palavras = len(texto.split())
        wpm = (palavras / duracao) * 60 if duracao > 0 else 0
        
        # Detectar pausas longas (>2s entre segmentos)
        if i > 0:
            pausa = inicio - result["segments"][i-1]["end"]
            if pausa > 2.0:
                estatisticas_tempo['pausas_longas'].append({
                    'tempo': inicio,
                    'duracao': pausa
                })
        
        transcricao_completa.append({
            'inicio': formatar_tempo(inicio),
            'fim': formatar_tempo(fim),
            'duracao': f"{duracao:.2f}s",
            'texto': texto,
            'palavras': palavras,
            'velocidade_wpm': f"{wpm:.1f}",
            'timestamp_raw': inicio
        })
        
        estatisticas_tempo['velocidade_fala'].append(wpm)
    
    return transcricao_completa, estatisticas_tempo
```

---

## üìä 3. Espectrograma "Terr√≠vel"

### **Problemas Identificados:**
- ‚ùå **Resolu√ß√£o baixa** (512 nperseg)
- ‚ùå **Escala inadequada** 
- ‚ùå **Colormap ruim**
- ‚ùå **Sem normaliza√ß√£o**

### **Espectrograma de Qualidade Forense:**
```python
def gerar_espectrograma_profissional(samples, sr, arquivo):
    """Espectrograma otimizado para an√°lise forense"""
    
    # Par√¢metros otimizados
    nperseg = min(2048, len(samples) // 8)  # Melhor resolu√ß√£o
    overlap = nperseg // 2                   # 50% overlap
    
    # Gerar espectrograma com alta resolu√ß√£o
    f, t, Sxx = spectrogram(
        samples, 
        fs=sr, 
        nperseg=nperseg,
        noverlap=overlap,
        window='hann'  # Janela Hann para melhor resolu√ß√£o
    )
    
    # Converter para dB com normaliza√ß√£o
    Sxx_db = 10 * np.log10(Sxx + 1e-10)
    
    # Criar figura com m√∫ltiplas visualiza√ß√µes
    fig = plt.figure(figsize=(16, 12))
    
    # 1. Espectrograma principal
    ax1 = plt.subplot(3, 1, 1)
    mappable = ax1.pcolormesh(
        t, f, Sxx_db, 
        shading='gouraud', 
        cmap='plasma',  # Colormap melhor que viridis
        vmin=np.percentile(Sxx_db, 10),  # Contraste din√¢mico
        vmax=np.percentile(Sxx_db, 95)
    )
    plt.colorbar(mappable, ax=ax1, label="Intensidade [dB]")
    ax1.set_ylabel("Frequ√™ncia [Hz]")
    ax1.set_title(f"Espectrograma Forense - {arquivo}")
    ax1.set_ylim(0, sr//2)  # Limitar at√© Nyquist
    
    # 2. Zoom em frequ√™ncias de voz (80-8000 Hz)
    ax2 = plt.subplot(3, 1, 2)
    voice_mask = (f >= 80) & (f <= 8000)
    mappable2 = ax2.pcolormesh(
        t, f[voice_mask], Sxx_db[voice_mask], 
        shading='gouraud', 
        cmap='plasma'
    )
    plt.colorbar(mappable2, ax=ax2, label="Intensidade [dB]")
    ax2.set_ylabel("Freq. Voz [Hz]")
    ax2.set_title("Zoom - Frequ√™ncias de Voz (80-8000 Hz)")
    
    # 3. An√°lise de energia temporal
    ax3 = plt.subplot(3, 1, 3)
    energia_temporal = np.sum(Sxx, axis=0)
    ax3.plot(t, 10 * np.log10(energia_temporal + 1e-10), 'b-', linewidth=1)
    ax3.set_xlabel("Tempo [s]")
    ax3.set_ylabel("Energia Total [dB]")
    ax3.set_title("Envelope de Energia Temporal")
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Salvar em alta qualidade
    plt.savefig(
        os.path.join(PASTA_OUT, f"{arquivo}_espectrograma_hd.png"), 
        dpi=300, 
        bbox_inches='tight',
        facecolor='white'
    )
    plt.close()
    
    return f, t, Sxx_db
```

---

## üé¨ 4. Extra√ß√£o de √Åudio de V√≠deo

### **Complexidade: BAIXA** ‚≠ê‚≠ê

### **Implementa√ß√£o Simples:**
```python
def extrair_audio_de_video(video_path, output_path):
    """Extrai √°udio de arquivo de v√≠deo"""
    try:
        command = [
            'ffmpeg', '-y',
            '-i', video_path,           # Input v√≠deo
            '-vn',                      # Sem v√≠deo
            '-acodec', 'pcm_s16le',     # Codec √°udio
            '-ar', '16000',             # Sample rate
            '-ac', '1',                 # Mono
            '-af', 'volume=1.5',        # Boost volume se necess√°rio
            output_path
        ]
        
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        return True
        
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro ao extrair √°udio: {e.stderr}")
        return False

# Adicionar ao processamento principal:
def processar_video_e_audio(path, pbar):
    """Processa v√≠deo extraindo √°udio primeiro"""
    base = os.path.splitext(os.path.basename(path))[0]
    
    # Verificar se √© v√≠deo
    video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.m4v'}
    if os.path.splitext(path)[1].lower() in video_extensions:
        
        # Extrair √°udio do v√≠deo
        audio_temp = os.path.join(PASTA_OUT, f"{base}_extracted.wav")
        if extrair_audio_de_video(path, audio_temp):
            # Processar o √°udio extra√≠do
            return processar_audio_simples(audio_temp, pbar)
    
    # Se n√£o √© v√≠deo, processar como √°udio normal
    return processar_audio_simples(path, pbar)
```

### **Formatos Suportados:**
- ‚úÖ MP4, AVI, MOV, MKV
- ‚úÖ WMV, FLV, M4V, WEBM
- ‚úÖ Qualquer formato que o FFmpeg suporte

---

## ü§ñ 5. Por que o Copilot √© "Maluco"?

### **Diferen√ßas T√©cnicas:**

| Aspecto | Claude (Eu) | Copilot |
|---------|-------------|---------|
| **Foco** | Conversa√ß√£o + An√°lise | Completar c√≥digo |
| **Contexto** | Toda conversa | Arquivo atual |
| **Objetivo** | Entender problema | Sugerir sintaxe |
| **An√°lise** | Arquitetura completa | Linha por linha |
| **Debugging** | Causa raiz | Fix r√°pido |

### **Por que Parece "Maluco":**

#### A) **Contexto Limitado:**
- ü§ñ Copilot: "V√™" s√≥ o arquivo atual
- üß† Claude: Entende o projeto completo

#### B) **Objetivo Diferente:**
- ü§ñ Copilot: "Complete esta linha"
- üß† Claude: "Resolva este problema"

#### C) **Treinamento:**
- ü§ñ Copilot: Baseado em GitHub (padr√µes)
- üß† Claude: Baseado em conversa√ß√µes (l√≥gica)

### **Quando Usar Cada Um:**
- **Copilot**: ‚úÖ Autocompletar, snippets, boilerplate
- **Claude**: ‚úÖ Arquitetura, debugging, an√°lise t√©cnica

---

## üõ†Ô∏è Implementa√ß√£o dos Ajustes

Quer que eu implemente essas melhorias agora? Posso criar:

1. **Script com detec√ß√£o inteligente** de picos/sil√™ncios
2. **Relat√≥rios com an√°lise temporal** completa  
3. **Espectrogramas HD** profissionais
4. **Suporte a v√≠deo** autom√°tico
5. **Configura√ß√£o flex√≠vel** para todos os par√¢metros

**Qual ajuste implemento primeiro?** üéØ